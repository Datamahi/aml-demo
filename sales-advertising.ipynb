{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Train, Test & Deploy: Advertising\n",
        "\n",
        "https://www.statlearning.com/s/Advertising.csv"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import azureml.core\n",
        "from azureml.core import Workspace\n",
        "from datetime import datetime\n",
        "\n",
        "# what version\n",
        "print(\"Azure ML SDK Version: \" + azureml.core.VERSION)\n",
        "\n",
        "%matplotlib inline"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1624876948535
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load workspace configuration\n",
        "ws = Workspace.from_config()\n",
        "\n",
        "print(\"Workspace name: \" + ws.name)\n",
        "print(\"Workspace location: \" + ws.location)\n",
        "print(\"Workspace resource group: \" + ws.resource_group)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1624876949079
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experiment setup"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create an azure ml experiment\n",
        "experiment_name = \"mmm-train\"\n",
        "\n",
        "from azureml.core import Experiment\n",
        "exp = Experiment(workspace=ws, name=experiment_name)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1624876949294
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compute clusters"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.compute import AmlCompute\n",
        "from azureml.core.compute import ComputeTarget\n",
        "import os\n",
        "\n",
        "# choose a name for your cluster\n",
        "compute_name = os.environ.get(\"AML_COMPUTE_CLUSTER_NAME\", \"cpu-cluster\")\n",
        "compute_min_nodes = os.environ.get(\"AML_COMPUTE_CLUSTER_MIN_NODES\", 0)\n",
        "compute_max_nodes = os.environ.get(\"AML_COMPUTE_CLUSTER_MAX_NODES\", 2)\n",
        "\n",
        "# This example uses CPU VM. For using GPU VM, set SKU to STANDARD_NC6\n",
        "vm_size = os.environ.get(\"AML_COMPUTE_CLUSTER_SKU\", \"STANDARD_D2_V2\")\n",
        "\n",
        "\n",
        "if compute_name in ws.compute_targets:\n",
        "    compute_target = ws.compute_targets[compute_name]\n",
        "    if compute_target and type(compute_target) is AmlCompute:\n",
        "        print(\"found compute target: \" + compute_name)\n",
        "else:\n",
        "    print(\"creating new compute target...\")\n",
        "    provisioning_config = AmlCompute.provisioning_configuration(vm_size = vm_size,\n",
        "                                                                min_nodes = compute_min_nodes, \n",
        "                                                                max_nodes = compute_max_nodes)\n",
        "\n",
        "    # create the cluster\n",
        "    compute_target = ComputeTarget.create(ws, compute_name, provisioning_config)\n",
        "    \n",
        "    # can poll for a minimum number of nodes and for a specific timeout. \n",
        "    # if no min node count is provided it will use the scale settings for the cluster\n",
        "    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
        "    \n",
        "     # For a more detailed view of current AmlCompute status, use get_status()\n",
        "    print(compute_target.get_status().serialize())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1624876949999
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#%%bash\n",
        "#mkdir data"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1624876950167
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Dataset\n",
        "import os\n",
        "\n",
        "dataset = Dataset.get_by_name(ws, name='advertising')\n",
        "\n",
        "dataset.download(target_path='./data', overwrite=True)\n",
        "\n",
        "if 'Advertising.csv' in os.listdir('./data'):\n",
        "    print(\"Dataset downloaded and in the right place!\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1624876956796
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#%%bash\n",
        "#mkdir training"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1624876957032
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile training/train.py\n",
        "\n",
        "import argparse\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import model_selection, metrics, linear_model\n",
        "import joblib\n",
        "from azureml.core import Run\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # let user feed in 2 parameters, the dataset to mount or download, and the regularization rate of the logistic regression model\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('--data-directory', type=str, dest='data_directory', help='data directory mounting point')\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    data_directory = args.data_directory\n",
        "\n",
        "    print(\"Reading input data\")\n",
        "\n",
        "    df = pd.read_csv(data_directory, index_col=0)\n",
        "\n",
        "    print(\"Complete\")\n",
        "\n",
        "    # target\n",
        "    y = df[\"sales\"]\n",
        "\n",
        "    # feature set\n",
        "    X = df.drop(columns=\"sales\")\n",
        "\n",
        "    print(\"Splitting data\")\n",
        "\n",
        "    # train/test split\n",
        "    X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.30, random_state=20)\n",
        "    \n",
        "    print(\"Complete\")\n",
        "\n",
        "    # get hold of the current run\n",
        "    run = Run.get_context()\n",
        "\n",
        "    print(\"Training\")\n",
        "\n",
        "    # initialise estimator\n",
        "    reg = linear_model.LinearRegression()\n",
        "    \n",
        "    # train\n",
        "    reg.fit(X_train, y_train)\n",
        "\n",
        "    print(\"Complete\")\n",
        "\n",
        "    # calculate in-sample root-mean-squared-error\n",
        "    in_sample_rmse = np.sqrt(metrics.mean_squared_error(y_train, reg.predict(X_train)))\n",
        "    \n",
        "    # print the rmse, this will appear in the log and will be captured by sagemaker\n",
        "    print(f\"IS-RMSE: {in_sample_rmse}\")\n",
        "\n",
        "    # log the metric result\n",
        "    run.log('in_sample_rmse', np.float(in_sample_rmse))\n",
        "\n",
        "    # make an output directory\n",
        "    os.makedirs('outputs', exist_ok=True)\n",
        "\n",
        "    # save the model\n",
        "    joblib.dump(value=reg, filename='outputs/reg.pkl')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.environment import Environment\n",
        "from azureml.core.conda_dependencies import CondaDependencies\n",
        "\n",
        "# to install required packages\n",
        "env = Environment('ml-env')\n",
        "cd = CondaDependencies.create(pip_packages=['azureml-dataset-runtime[pandas,fuse]', 'azureml-defaults'], conda_packages = ['scikit-learn==0.22.1'])\n",
        "\n",
        "env.python.conda_dependencies = cd\n",
        "\n",
        "# Register environment to re-use later\n",
        "env.register(workspace = ws)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1624876957464
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import ScriptRunConfig\n",
        "\n",
        "args = ['--data-directory', dataset.as_mount()]\n",
        "\n",
        "src = ScriptRunConfig(source_directory=\"./training\",\n",
        "                      script='train.py', \n",
        "                      arguments=args,\n",
        "                      compute_target=compute_target,\n",
        "                      environment=env)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1624876957715
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run = exp.submit(config=src)\n",
        "run"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1624876960694
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.widgets import RunDetails\n",
        "RunDetails(run).show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1624876961208
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# specify show_output to True for a verbose log\n",
        "run.wait_for_completion(show_output=True) "
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1624877544507
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(run.get_metrics())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1624877544810
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(run.get_file_names())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1624877545013
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# register model \n",
        "model = run.register_model(model_name='mmm', model_path='outputs/reg.pkl')\n",
        "print(model.name, model.id, model.version, sep='\\t')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1624877545586
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#%%bash\n",
        "#mkdir scoring"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile scoring/score.py\n",
        "import json\n",
        "import numpy as np\n",
        "import os\n",
        "import pickle\n",
        "import joblib\n",
        "\n",
        "def init():\n",
        "    global model\n",
        "    # AZUREML_MODEL_DIR is an environment variable created during deployment.\n",
        "    # It is the path to the model folder (./azureml-models/$MODEL_NAME/$VERSION)\n",
        "    # For multiple models, it points to the folder containing all deployed models (./azureml-models)\n",
        "    model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'reg.pkl')\n",
        "    model = joblib.load(model_path)\n",
        "\n",
        "def run(raw_data):\n",
        "    data = np.array(json.loads(raw_data)['data'])\n",
        "    # make prediction\n",
        "    y_hat = model.predict(data)\n",
        "    # you can return any data type as long as it is JSON-serializable\n",
        "    return y_hat.tolist()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.webservice import AciWebservice\n",
        "\n",
        "aciconfig = AciWebservice.deploy_configuration(cpu_cores=1, \n",
        "                                               memory_gb=1, \n",
        "                                               tags={\"data\": \"Advertising\",  \"method\" : \"sklearn\"}, \n",
        "                                               description='Predict Sales')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1624883173387
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "import uuid\n",
        "from azureml.core.webservice import Webservice\n",
        "from azureml.core.model import InferenceConfig\n",
        "from azureml.core.model import Model\n",
        "\n",
        "model = Model(ws, 'mmm')\n",
        "\n",
        "inference_config = InferenceConfig(entry_script=\"scoring/score.py\", environment=env)\n",
        "\n",
        "service_name = 'mmm-reg' + str(uuid.uuid4())[:4]\n",
        "service = Model.deploy(workspace=ws, \n",
        "                       name=service_name, \n",
        "                       models=[model], \n",
        "                       inference_config=inference_config, \n",
        "                       deployment_config=aciconfig)\n",
        "\n",
        "service.wait_for_deployment(show_output=True)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "input_data = \"{\\\"data\\\": [\" + str([20, 100, 50]) + \"]}\"\n",
        "\n",
        "headers = {'Content-Type':'application/json'}\n",
        "\n",
        "resp = requests.post(service.scoring_uri, input_data, headers=headers)\n",
        "\n",
        "print(\"POST to url\", service.scoring_uri)\n",
        "\n",
        "print(\"prediction:\", resp.text)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1624884255458
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.1",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}